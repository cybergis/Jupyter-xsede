{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducible Hydrological Modeling with CyberGIS-Jupyter For Water (CJW) and HydroShare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Fangzheng$ $Lyu^{1}$, $Zhiyu$ $Li^{1}$, $Anand$ $Padmanabhan^{1}$, $Shaowen$ $Wang^{1}$, $Youngdon$ $Choi^{2}$, $Jonathan$ $Goodall^{2}$, $Andrew$ $Bennett^{3}$, $Bart$ $Nijssen^{3}$, $David$ $Tarboton^{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$^{1}$ $University$ $of$ $Illinois$ $at$ $Urbana-Champaign$; $^{2}$ $University$ $of$ $Virginia$; $^{3}$ $University$ $of$ $Washington$; $^{4}$ $Utah$ $State$ $University$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CyberGIS-Jupyter for Water (CJW), leveraging the cyberGIS software ecosystem, is integrated with HydroShare. CJW provides a collaborative platform for enabling computationally intensive and reproducible hydrologic research by delivering advanced cyberinfrastructure and cyberGIS capabilities based on high-performance computing (HPC) resources such as Virtual ROGER and XSEDE Comet. The Structure For Unifying Multiple Modeling Alternatives [(SUMMA)](https://ral.ucar.edu/projects/summa), which is a hydrological modeling framework, allows for formal evaluation of multiple working hypotheses on model representations of physical processes. This CyberGIS-Jupyter notebook illustrates specific support for a SUMMA model on top of the cutting-edge hydrologic modeling capabilities on CJW. By taking advantage of CJW, users can easily tune different parameters for a SUMMA model and submit computationally intensive High-Throughput Computing (HTC) jobs for executing the model on HPC resources via Jupyter notebooks without having to possess in-depth technical knowledge about cyberGIS or HydroShare. Computational experiments demonstrate that the integration of cyberGIS capabilities and HydroShare achieves a high-performance and easy-to-use environment for reproducible SUMMA-based hydrological modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Outline\n",
    "- [The Structure For Unifying Multiple Modeling Alternatives (SUMMA)](#summa)\n",
    "- [Architecture](#arch)\n",
    "- [Retrieve resources](#resources)\n",
    "- [Unzip model instance package](#unzip)\n",
    "- [Install SUMMA model](#install)\n",
    "- [Use pySUMMA to build ensembles](#build)\n",
    "- [Submit model](#submit)\n",
    "- [Check model output](#check)\n",
    "- [Plot the output](#plot)\n",
    "    - [Leaf Area Index & ET](#LAI)\n",
    "    - [stomatal resistance & ET](#stomatal)\n",
    "- [Cleanup](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summa'></a>\n",
    "## The Structure For Unifying Multiple Modeling Alternatives (SUMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMA or the Structure for Unifying Multiple Modeling Alternatives is a hydrologic modeling approach that is built on a common set of conservation equations and a common numerical solver, which together constitute the structural core of the model. Different modeling approaches can then be implemented within the structural core, enabling a controlled and systematic analysis of alternative modeling options, and providing insight for future model development.\n",
    "1. The formulation of the conservation equations is cleanly separated from their numerical solution;\n",
    "2. Different model representations of physical processes (in particular, different flux parameterizations) can be used within a common set of conservation equations; and\n",
    "3. The physical processes can be organized in different spatial configurations, including model elements of different shape and connectivity (e.g., nested multi-scale grids and HRUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arch'></a>\n",
    "## Architecture of Job Submission System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of job submission system is listed as follows. The architecture of the integrated system enables interactions among three key entities: users, CyberGIS-Jupyter, and HPC resources provided through cyberGIS platform (e.g. keeling). In addition, there are four supporting components with which the key entities interact with: 1) external authentication system, 2) HydroShare for hydrological data retrieval, 3) JupyterHub with appropriate cyberGIS and geospatial python libraries installed, and 4) Docker hub for SUMMA singularity image. HydroShare is a collaborative research platform for advancing hydrological data and model sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Picture/SUMMA_Architecture.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='resources'></a>\n",
    "## Retrieve a SUMMA model instance resource from HydroShare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the resource id of a HydroShare composite resource that contains a SUMMA model instance. More information on this [resource](https://www.hydroshare.org/resource/1f3f310af8364d2aa3e6a9459152a21c/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the resource ID\n",
    "resource_id = '1f3f310af8364d2aa3e6a9459152a21c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use HydroShare REST API Python client (hs_restclient) to retrieve the above resource onto the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Import json, os, hs_restclient, subprocess library\n",
    "import json\n",
    "import os\n",
    "from hs_restclient import HydroShare, HydroShareAuthBasic\n",
    "import subprocess\n",
    "# Connect with HydroShare\n",
    "auth = HydroShareAuthBasic(\"cybergis\", \"demo\")\n",
    "hs = HydroShare(auth=auth)\n",
    "# Dictionary path\n",
    "base_dir = os.path.abspath('/home/jovyan/work')\n",
    "download_dir = \"/home/jovyan/shared_data/data/tmp_job_submit\"\n",
    "# Get the metadata of the resource\n",
    "metadata = hs.getScienceMetadata(resource_id)\n",
    "timestamp = resource_id+\";\"+metadata['dates'][1]['start_date']\n",
    "# Test if the file is located in the shared folder\n",
    "out = subprocess.Popen(['ls',  '/home/jovyan/shared_data/data/tmp_job_submit'], \n",
    "           stdout=subprocess.PIPE, \n",
    "           stderr=subprocess.STDOUT)\n",
    "stdout,stderr = out.communicate()\n",
    "out2 = subprocess.Popen(['grep', timestamp, '/home/jovyan/shared_data/data/tmp_job_submit/managementfile'], \n",
    "           stdout=subprocess.PIPE, \n",
    "           stderr=subprocess.STDOUT)\n",
    "stdout2,stderr2 = out2.communicate()\n",
    "# when the resource is not available in the shared folder\n",
    "if (resource_id.encode(\"utf-8\") not in stdout or stdout2==b\"\"):\n",
    "    print(\"Downloading Data\")\n",
    "    #!mkdir -p {download_dir}\n",
    "    hs.getResource(resource_id, destination=download_dir, unzip=True)\n",
    "    with open('/home/jovyan/shared_data/data/tmp_job_submit/managementfile', 'a') as file:\n",
    "        file.write(timestamp)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='unzip'></a>\n",
    "## Unzip model instance package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary local folder and unzip the SUMMA instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SummaModel_ReynoldsAspenStand_StomatalResistance_sopron.zip\n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/\n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/\n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/forcingData/\n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/forcingData/forcing_above_aspen.nc  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/reynolds_geojson_latlon.geojson  \n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/validationData/\n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/data/validationData/ReynoldsCreek_eddyFlux.nc  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/installTestCases_local.sh  \n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/output/\n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/\n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/GENPARM.TBL  \n",
      "   creating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/\n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/dos2unix.sh  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/Model_Output.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zBasinModelVarMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zBasinParamMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zCategoryMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zForceMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zLocalAttributeMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zLocalModelIndexMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zLocalModelVarMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zLocalParamMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zModelIndexMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zParamMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/summa_zTimeMeta.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/meta/var_lookup.f90  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/MPTABLE.TBL  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/SOILPARM.TBL  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_fileManager_riparianAspenSimpleResistance.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zBasinParamInfo.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zDecisions_riparianAspenSimpleResistance.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zForcingFileList_riparianAspen.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zForcingInfo_riparianAspen.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zInitialCond.nc  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zLocalAttributes_riparianAspen.nc  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zLocalParamInfo.txt  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zParamTrial_riparianAspen.nc  \n",
      "  inflating: /home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/VEGPARM.TBL  \n",
      "Unzipping Done\n"
     ]
    }
   ],
   "source": [
    "# Import os, tempfile library\n",
    "import os\n",
    "import tempfile\n",
    "# Unzip model file\n",
    "model_folder_name = \"SummaModel_ReynoldsAspenStand_StomatalResistance_sopron\"\n",
    "content_folder = os.path.join(download_dir ,\"{}/{}/data/contents\".format(resource_id, resource_id))\n",
    "file_manger_rel_path = \"settings/summa_fileManager_riparianAspenSimpleResistance.txt\"\n",
    "workspace_dir = os.path.join(base_dir, 'workspace')\n",
    "!mkdir -p {workspace_dir}\n",
    "unzip_dir = tempfile.mkdtemp(dir=workspace_dir)\n",
    "!cd {content_folder} && unzip -o {model_folder_name}.zip -d {unzip_dir}\n",
    "print(\"Unzipping Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='install'></a>\n",
    "## Install SUMMA model on Jupyter server (configure path in summa file_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the file_manager file of the SUMMA instance does not contain local path. Need to use script to install it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestCases installed\n"
     ]
    }
   ],
   "source": [
    "# Install the testcases\n",
    "model_source_folder_path = os.path.join(unzip_dir, model_folder_name)\n",
    "!cd {model_source_folder_path} && chmod +x ./installTestCases_local.sh\n",
    "!cd {model_source_folder_path} && ./installTestCases_local.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build'></a>\n",
    "## Use pySUMMA to build ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an empty \"summa_zParamTrial_riparianAspen.nc\" file so later we can do ensemble analysis on parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/workspace/tmpiy2p3jr5/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/settings/summa_zParamTrial_riparianAspen.nc\n"
     ]
    }
   ],
   "source": [
    "# Create a empty ParamTrial.nc file (required by parameter ensemble)\n",
    "import netCDF4 as nc\n",
    "name = os.path.join(model_source_folder_path, 'settings/summa_zParamTrial_riparianAspen.nc')\n",
    "print(name)\n",
    "param_trial = nc.Dataset(name, \"w\", format=\"NETCDF3_CLASSIC\")\n",
    "param_trial.createDimension(\"hru\", 1)\n",
    "param_trial.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the ensemble cases: here we create a combination of different stomResist types, rootDistExp values and summerLAI values with help from PySumma. The total ensemble number is 75. We then save the 75 cases into a json file named \"summa_options.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ensemble runs: 75\n",
      "{\n",
      "    \"++BallBerry++rootDistExp=0.01++summerLAI=0.01++\": {\n",
      "        \"decisions\": {\n",
      "            \"stomResist\": \"BallBerry\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"rootDistExp\": 0.01,\n",
      "            \"summerLAI\": 0.01\n",
      "        }\n",
      "    },\n",
      "    \"++BallBerry++rootDistExp=0.01++summerLAI=2.01++\": {\n",
      "        \"decisions\": {\n",
      "            \"stomResist\": \"BallBerry\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"rootDistExp\": 0.01,\n",
      "            \"summerLAI\": 2.01\n",
      "        }\n",
      "    },\n",
      "    \"++BallBerry++rootDistExp=0.01++summerLAI=4.01++\": {\n",
      "        \"decisions\": {\n",
      "            \"stomResist\": \"BallBerry\"\n",
      "        },\n",
      "        \"parameters\": {\n",
      "            \"rootDistExp\": 0.01,\n",
      "            \"summerLAI\": 4.01\n",
      "        }\n",
      "    },\n",
      "    \"++BallBerry++rootDistExp=0.01++summerLAI=6.01++\": {\n",
      "        \"decisions\": {\n",
      "            \"stomRe\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import json\n",
    "from pysumma import ensemble\n",
    "\n",
    "def safe_arange(start, stop, step):\n",
    "    a = np.arange(start, stop, step)\n",
    "    result =[]\n",
    "    for i in a:\n",
    "        par = round(i, 10)\n",
    "        result = np.append(result, par)\n",
    "    return result\n",
    "\n",
    "# create ensemble\n",
    "# different parameterizations\n",
    "decision_options = {\n",
    "    \"stomResist\": [\"BallBerry\", \"Jarvis\", \"simpleResistance\"]\n",
    "}\n",
    "# different parameters\n",
    "param_options = {\n",
    "   'rootDistExp': safe_arange(0.01, 1.00, 0.20),\n",
    "   'summerLAI': safe_arange(0.01, 10.00, 2.00)\n",
    "}\n",
    "\n",
    "config = ensemble.total_product(dec_conf=decision_options, param_conf=param_options)\n",
    "\n",
    "# save ensemble info to json file\n",
    "with open(os.path.join(model_source_folder_path, 'summa_options.json'), 'w') as outfile:\n",
    "    json.dump(config, outfile)\n",
    "\n",
    "# check ensemble parameters    \n",
    "print(\"Number of ensemble runs: {}\".format(len(config)))\n",
    "print(json.dumps(config, indent=4, sort_keys=True)[:800])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='submit'></a>\n",
    "## Submit model to Virtual Roger (Keeling) HPC using CyberGIS-Jupyter tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cybergis lib to submit the HTC SUMMA model to High-Performance Computer as a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:56:44,147 [MainThread  ] [INFO ]  SSH logged into keeling.earth.illinois.edu as user cigi-gisolve\n",
      "2020-05-13 17:56:44,154 [MainThread  ] [INFO ]  Uploading /home/jovyan/work/workspace/Summa_1589392601_cc8da06c to /data/keeling/a/cigi-gisolve\n",
      "2020-05-13 17:56:47,928 [MainThread  ] [INFO ]  Submitting Job summa.sbatch to queue\n",
      "2020-05-13 17:56:48,436 [MainThread  ] [INFO ]  Remote Job ID assigned: 3549901\n",
      "2020-05-13 17:56:52,013 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:03,382 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:06,917 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:11,516 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:15,113 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:19,150 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:22,833 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:26,420 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:30,336 [MainThread  ] [INFO ]  R\n",
      "2020-05-13 17:57:34,822 [MainThread  ] [INFO ]  Job completed: Summa_1589392601_cc8da06c; 3549901\n",
      "2020-05-13 17:57:34,823 [MainThread  ] [INFO ]  Downloading /data/keeling/a/cigi-gisolve/Summa_1589392601_cc8da06c/SummaModel_ReynoldsAspenStand_StomatalResistance_sopron/output to /home/jovyan/work/workspace/Summa_1589392601_cc8da06c\n"
     ]
    }
   ],
   "source": [
    "## Submit the job directly without UI\n",
    "from cybergis import HPCSUMMA\n",
    "dict_ = {}\n",
    "dict_[\"model\"] = \"summa\"\n",
    "dict_[\"model_source_folder_path\"] = model_source_folder_path\n",
    "dict_[\"file_manger_rel_path\"] = file_manger_rel_path\n",
    "dict_[\"workspace_dir\"] = workspace_dir\n",
    "dict_[\"machine\"] = \"keeling\"\n",
    "dict_['node'] = 16\n",
    "dict_['walltime'] = 1\n",
    "\n",
    "para_json_str = json.dumps(dict_)\n",
    "\n",
    "s = HPCSUMMA(para_json_str)\n",
    "s.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walltime (hour) is the maximum duration of time the job is allowed to run on the HPC before it gets killed.\n",
    "Nodes indicate the number of CPU cores will be allocated for this job. CyberGIS lib will run the job over the assigned CPUs in parallel. If you select 16 nodes, then each node will run about 4-5 cases out of the 75-member ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='check'></a>\n",
    "## Check model output  -- NetCDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once job finishes execution on HPC, cybergis lib will retrieve the results back to notebook server. Each ensemble member will create a separate nc file, so there are 75 netcdf files in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output directory\n",
    "job_dir = os.path.join(workspace_dir, \"{}\".format(s.job_local_id))\n",
    "output_path = os.path.join(job_dir, \"output\")\n",
    "# check SUMMA output file \n",
    "name_list = os.listdir(output_path)\n",
    "full_list = [os.path.join(output_path,i) for i in name_list if i.endswith(\".nc\")]\n",
    "sorted_list = sorted(full_list)\n",
    "\n",
    "for f in sorted_list:\n",
    "    print(f)\n",
    "print(\"Number of NC files: {}\".format(len(sorted_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "## Plot time series for total evapotranspiration (total ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a functions that can read in a list of Summa output nc files, calculate Total evapotranspiration and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "%matplotlib inline\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#  Function to calculate the total evapotranspiration\n",
    "def calc_total_et(et_output_df):\n",
    "    total_et_data = (et_output_df['scalarLatHeatTotal'])*3600/2260000\n",
    "    # create dates(X-axis) attribute from ouput netcdf\n",
    "    dates = total_et_data.coords['time'].data\n",
    "    # create data value(Y-axis) attribute from ouput netcdf\n",
    "    data_values = total_et_data.data\n",
    "    # create two dimensional tabular data structure \n",
    "    total_et_df = pd.DataFrame(data_values, index=dates)\n",
    "    # round time to nearest hour (ex. 2006-10-01T00:59:59.99 -> 2006-10-01T01:00:00)\n",
    "    total_et_df.index = total_et_df.index.round(\"H\")\n",
    "    # set the time period to display plot \n",
    "    total_et_df = total_et_df.loc[\"2007-05-31 23:00:00\":\"2007-08-20 23:00:00\"]\n",
    "    # resample data by the average value hourly\n",
    "    total_et_df_hourly = total_et_df.resample(\"H\").mean()\n",
    "    # resample data by the average for hour of day\n",
    "    total_et_by_hour = total_et_df_hourly.groupby(total_et_df_hourly.index.hour).mean()\n",
    "    total_et_by_hour.index.name = 'hour'\n",
    "    total_et_by_hour.columns = ['ET']\n",
    "    # calculate 3 hour moving average\n",
    "    total_et_by_hour.loc[24] = total_et_by_hour.loc[0].values\n",
    "    for index in range(1,24,1):\n",
    "        total_et_by_hour['ET'][index] = (total_et_by_hour['ET'][index-1]+total_et_by_hour['ET'][index]+total_et_by_hour['ET'][index+1])/3\n",
    "    return total_et_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ET1(nc_list):\n",
    "    \n",
    "    dataset_list = [calc_total_et(xr.open_dataset(nc)) for nc in nc_list]\n",
    "    ET_Combine = pd.concat(dataset_list, axis=1)\n",
    "    ET_Combine_Graph = ET_Combine.plot(linewidth=3.0,figsize=(12,10))\n",
    "    # invert y axis\n",
    "    ET_Combine_Graph.invert_yaxis()\n",
    "\n",
    "    # add x, y label\n",
    "    plt.xlabel('Time of day (hr)', fontsize=25)\n",
    "    plt.ylabel('Total evapotranspiration (mm/h)', fontsize=25)\n",
    "    # show up the legend\n",
    "    legends = []\n",
    "    for nc in nc_list:\n",
    "        legends.append(os.path.basename(nc))\n",
    "    #for lengend in legends:\n",
    "    legend = []\n",
    "    for lists in legends:\n",
    "        list = lists.split(\"++\")[3]\n",
    "        legend.append(list)\n",
    "    ET_Combine_Graph.legend(legend, fontsize=20, loc=2)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='LAI'></a>\n",
    "### How do different  Leaf Area Index (summerLAI) values affect total ET?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the ET results for different summaLAI by setting stomResist to BallBerry and rootDistExp=0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [x for x in sorted_list if 'BallBerry++rootDistExp=0.21' in x]\n",
    "plot_ET1(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stomatal'></a>\n",
    "### How do different  stomatal resistance parameterizations affect total ET?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we only plot the ET results for different stomResist types by setting rootDistExp=0.21 and summerLAI to 4.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ET1(nc_list):\n",
    "    \n",
    "    dataset_list = [calc_total_et(xr.open_dataset(nc)) for nc in nc_list]\n",
    "    ET_Combine = pd.concat(dataset_list, axis=1)\n",
    "    ET_Combine_Graph = ET_Combine.plot(linewidth=3.0,figsize=(12,10))\n",
    "    # invert y axis\n",
    "    ET_Combine_Graph.invert_yaxis()\n",
    "\n",
    "    # add x, y label\n",
    "    #ET_Combine_Graph.set(xlabel='Time of day (hr)', ylabel='Total evapotranspiration (mm h-1)', fontsize=25)\n",
    "    plt.xlabel('Time of day (hr)', fontsize=25)\n",
    "    plt.ylabel('Total evapotranspiration (mm/h)', fontsize=25)\n",
    "    # show up the legend\n",
    "    legends = []\n",
    "    for nc in nc_list:\n",
    "        legends.append(os.path.basename(nc))\n",
    "    #for lengend in legends:\n",
    "    legend = []\n",
    "    for lists in legends:\n",
    "        list = lists.split(\"++\")[1]\n",
    "        legend.append(list)\n",
    "    ET_Combine_Graph.legend(legend, fontsize=20, loc=2)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [x for x in sorted_list if 'rootDistExp=0.21++summerLAI=4.01' in x]\n",
    "plot_ET1(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanup'></a>\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is optional, which will remove all model outputs on notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rvf {unzip_dir} {job_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydro-Python3",
   "language": "python",
   "name": "hydro-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
